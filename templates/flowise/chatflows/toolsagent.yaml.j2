# this chatflow was exported from the UI and
# then templated using non-standard "[%" and
# "%]" variable markers because Flowise uses
# "{{ ... }}" to reference other graph nodes
# NOTE: .credential properties must be added
# under .data, not .inputs
#
# pass the following vars:
#   openai_cred_id
#   openai_model:
#     name
#     temperature
#     top_p
#   memory_window
#   date_tool_id
#   serp_cred_id
---
nodes:
  - id: toolAgent_0
    position:
      x: 1050
      y: 1225
    type: customNode
    data:
      id: toolAgent_0
      label: Tool Agent
      version: 2
      name: toolAgent
      type: AgentExecutor
      baseClasses:
        - AgentExecutor
        - BaseChain
        - Runnable
      category: Agents
      description: Agent that uses Function Calling to pick the tools and args to call
      inputParams:
        - label: System Message
          name: systemMessage
          type: string
          default: You are a helpful AI assistant.
          description: If Chat Prompt Template is provided, this will be ignored
          rows: 4
          optional: true
          additionalParams: true
          id: toolAgent_0-input-systemMessage-string
          display: true
        - label: Max Iterations
          name: maxIterations
          type: number
          optional: true
          additionalParams: true
          id: toolAgent_0-input-maxIterations-number
          display: true
        - label: Enable Detailed Streaming
          name: enableDetailedStreaming
          type: boolean
          default: false
          description: Stream detailed intermediate steps during agent execution
          optional: true
          additionalParams: true
          id: toolAgent_0-input-enableDetailedStreaming-boolean
          display: true
      inputAnchors:
        - label: Tools
          name: tools
          type: Tool
          list: true
          id: toolAgent_0-input-tools-Tool
          display: true
        - label: Memory
          name: memory
          type: BaseChatMemory
          id: toolAgent_0-input-memory-BaseChatMemory
          display: true
        - label: Tool Calling Chat Model
          name: model
          type: BaseChatModel
          description: 'Only compatible with models that are capable of function calling: ChatOpenAI, ChatMistral, ChatAnthropic, ChatGoogleGenerativeAI, ChatVertexAI, GroqChat'
          id: toolAgent_0-input-model-BaseChatModel
          display: true
        - label: Chat Prompt Template
          name: chatPromptTemplate
          type: ChatPromptTemplate
          description: Override existing prompt with Chat Prompt Template. Human Message must includes {input} variable
          optional: true
          id: toolAgent_0-input-chatPromptTemplate-ChatPromptTemplate
          display: true
        - label: Input Moderation
          description: Detect text that could generate harmful output and prevent it from being sent to the language model
          name: inputModeration
          type: Moderation
          optional: true
          list: true
          id: toolAgent_0-input-inputModeration-Moderation
          display: true
      inputs:
        tools:
          - '{{customTool_0.data.instance}}'
          - '{{serpAPI_0.data.instance}}'
          - '{{calculator_0.data.instance}}'
        memory: '{{bufferWindowMemory_0.data.instance}}'
        model: '{{chatOpenAI_0.data.instance}}'
        chatPromptTemplate: ""
        systemMessage: You are a helpful AI assistant.
        inputModeration: ""
        maxIterations: ""
        enableDetailedStreaming: ""
      outputAnchors:
        - id: toolAgent_0-output-toolAgent-AgentExecutor|BaseChain|Runnable
          name: toolAgent
          label: AgentExecutor
          description: Agent that uses Function Calling to pick the tools and args to call
          type: AgentExecutor | BaseChain | Runnable
      outputs: {}
      selected: false
    width: 300
    height: 535
    positionAbsolute:
      x: 1050
      y: 1225
    selected: false
    dragging: false
  - id: chatOpenAI_0
    position:
      x: 700
      y: 1125
    type: customNode
    data:
      id: chatOpenAI_0
      label: ChatOpenAI
      version: 8.3
      name: chatOpenAI
      type: ChatOpenAI
      baseClasses:
        - ChatOpenAI
        - BaseChatOpenAI
        - BaseChatModel
        - BaseLanguageModel
        - Runnable
      category: Chat Models
      description: Wrapper around OpenAI large language models that use the Chat endpoint
      inputParams:
        - label: Connect Credential
          name: credential
          type: credential
          credentialNames:
            - openAIApi
          id: chatOpenAI_0-input-credential-credential
          display: true
        - label: Model Name
          name: modelName
          type: asyncOptions
          loadMethod: listModels
          default: gpt-4o-mini
          id: chatOpenAI_0-input-modelName-asyncOptions
          display: true
        - label: Temperature
          name: temperature
          type: number
          step: 0.1
          default: 0.9
          optional: true
          id: chatOpenAI_0-input-temperature-number
          display: true
        - label: Streaming
          name: streaming
          type: boolean
          default: true
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-streaming-boolean
          display: true
        - label: Max Tokens
          name: maxTokens
          type: number
          step: 1
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-maxTokens-number
          display: true
        - label: Top Probability
          name: topP
          type: number
          step: 0.1
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-topP-number
          display: true
        - label: Frequency Penalty
          name: frequencyPenalty
          type: number
          step: 0.1
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-frequencyPenalty-number
          display: true
        - label: Presence Penalty
          name: presencePenalty
          type: number
          step: 0.1
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-presencePenalty-number
          display: true
        - label: Timeout
          name: timeout
          type: number
          step: 1
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-timeout-number
          display: true
        - label: Strict Tool Calling
          name: strictToolCalling
          type: boolean
          description: Whether the model supports the `strict` argument when passing in tools. If not specified, the `strict` argument will not be passed to OpenAI.
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-strictToolCalling-boolean
          display: true
        - label: Stop Sequence
          name: stopSequence
          type: string
          rows: 4
          optional: true
          description: List of stop words to use when generating. Use comma to separate multiple stop words.
          additionalParams: true
          id: chatOpenAI_0-input-stopSequence-string
          display: true
        - label: BasePath
          name: basepath
          type: string
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-basepath-string
          display: true
        - label: Proxy Url
          name: proxyUrl
          type: string
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-proxyUrl-string
          display: true
        - label: BaseOptions
          name: baseOptions
          type: json
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-baseOptions-json
          display: true
        - label: Allow Image Uploads
          name: allowImageUploads
          type: boolean
          description: Allow image input. Refer to the <a href="https://docs.flowiseai.com/using-flowise/uploads#image" target="_blank">docs</a> for more details.
          default: false
          optional: true
          id: chatOpenAI_0-input-allowImageUploads-boolean
          display: true
        - label: Image Resolution
          description: This parameter controls the resolution in which the model views the image.
          name: imageResolution
          type: options
          options:
            - label: Low
              name: low
            - label: High
              name: high
            - label: Auto
              name: auto
          default: low
          optional: false
          show:
            allowImageUploads: true
          id: chatOpenAI_0-input-imageResolution-options
          display: false
        - label: Reasoning
          description: Whether the model supports reasoning. Only applicable for reasoning models.
          name: reasoning
          type: boolean
          default: false
          optional: true
          additionalParams: true
          id: chatOpenAI_0-input-reasoning-boolean
          display: true
        - label: Reasoning Effort
          description: Constrains effort on reasoning for reasoning models
          name: reasoningEffort
          type: options
          options:
            - label: Low
              name: low
            - label: Medium
              name: medium
            - label: High
              name: high
          additionalParams: true
          show:
            reasoning: true
          id: chatOpenAI_0-input-reasoningEffort-options
          display: false
        - label: Reasoning Summary
          description: A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process
          name: reasoningSummary
          type: options
          options:
            - label: Auto
              name: auto
            - label: Concise
              name: concise
            - label: Detailed
              name: detailed
          additionalParams: true
          show:
            reasoning: true
          id: chatOpenAI_0-input-reasoningSummary-options
          display: false
      inputAnchors:
        - label: Cache
          name: cache
          type: BaseCache
          optional: true
          id: chatOpenAI_0-input-cache-BaseCache
          display: true
      inputs:
        cache: '{{inMemoryCache_0.data.instance}}'
        modelName: [% openai_model.name %]
        temperature: "[% openai_model.temperature %]"
        streaming: true
        maxTokens: ""
        topP: "[% openai_model.top_p %]"
        frequencyPenalty: ""
        presencePenalty: ""
        timeout: ""
        strictToolCalling: ""
        stopSequence: ""
        basepath: ""
        proxyUrl: ""
        baseOptions: ""
        allowImageUploads: ""
        imageResolution: low
        reasoning: ""
        reasoningEffort: ""
        reasoningSummary: ""
      outputAnchors:
        - id: chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable
          name: chatOpenAI
          label: ChatOpenAI
          description: Wrapper around OpenAI large language models that use the Chat endpoint
          type: ChatOpenAI | BaseChatOpenAI | BaseChatModel | BaseLanguageModel | Runnable
      outputs: {}
      credential: [% openai_cred_id %]
      selected: false
    width: 300
    height: 735
    selected: false
    positionAbsolute:
      x: 700
      y: 1125
    dragging: false
  - id: inMemoryCache_0
    position:
      x: 0
      y: 1530
    type: customNode
    data:
      id: inMemoryCache_0
      label: InMemory Cache
      version: 1
      name: inMemoryCache
      type: InMemoryCache
      baseClasses:
        - InMemoryCache
        - BaseCache
      category: Cache
      description: Cache LLM response in memory, will be cleared once app restarted
      inputParams: []
      inputAnchors: []
      inputs: {}
      outputAnchors:
        - id: inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache
          name: inMemoryCache
          label: InMemoryCache
          description: Cache LLM response in memory, will be cleared once app restarted
          type: InMemoryCache | BaseCache
      outputs: {}
      selected: false
    width: 300
    height: 159
    selected: false
    dragging: false
    positionAbsolute:
      x: 0
      y: 1530
  - id: bufferWindowMemory_0
    position:
      x: 0
      y: 1125
    type: customNode
    data:
      id: bufferWindowMemory_0
      label: Buffer Window Memory
      version: 2
      name: bufferWindowMemory
      type: BufferWindowMemory
      baseClasses:
        - BufferWindowMemory
        - BaseChatMemory
        - BaseMemory
      category: Memory
      description: Uses a window of size k to surface the last k back-and-forth to use as memory
      inputParams:
        - label: Size
          name: k
          type: number
          default: "4"
          description: Window of size k to surface the last k back-and-forth to use as memory.
          id: bufferWindowMemory_0-input-k-number
          display: true
        - label: Session Id
          name: sessionId
          type: string
          description: If not specified, a random id will be used. Learn <a target="_blank" href="https://docs.flowiseai.com/memory#ui-and-embedded-chat">more</a>
          default: ""
          optional: true
          additionalParams: true
          id: bufferWindowMemory_0-input-sessionId-string
          display: true
        - label: Memory Key
          name: memoryKey
          type: string
          default: chat_history
          additionalParams: true
          id: bufferWindowMemory_0-input-memoryKey-string
          display: true
      inputAnchors: []
      inputs:
        k: "[% memory_window %]"
        sessionId: ""
        memoryKey: chat_history
      outputAnchors:
        - id: bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory
          name: bufferWindowMemory
          label: BufferWindowMemory
          description: Uses a window of size k to surface the last k back-and-forth to use as memory
          type: BufferWindowMemory | BaseChatMemory | BaseMemory
      outputs: {}
      selected: false
    width: 300
    height: 367
    selected: false
    positionAbsolute:
      x: 0
      y: 1125
    dragging: false
  - id: customTool_0
    position:
      x: 350
      y: 1125.5
    type: customNode
    data:
      id: customTool_0
      label: Custom Tool
      version: 3
      name: customTool
      type: CustomTool
      baseClasses:
        - CustomTool
        - Tool
        - StructuredTool
        - Runnable
      category: Tools
      description: Use custom tool you've created in Flowise within chatflow
      inputParams:
        - label: Select Tool
          name: selectedTool
          type: asyncOptions
          loadMethod: listTools
          id: customTool_0-input-selectedTool-asyncOptions
          display: true
        - label: Return Direct
          name: returnDirect
          description: Return the output of the tool directly to the user
          type: boolean
          optional: true
          id: customTool_0-input-returnDirect-boolean
          display: true
        - label: Custom Tool Name
          name: customToolName
          type: string
          hidden: true
          id: customTool_0-input-customToolName-string
          display: true
        - label: Custom Tool Description
          name: customToolDesc
          type: string
          hidden: true
          id: customTool_0-input-customToolDesc-string
          display: true
        - label: Custom Tool Schema
          name: customToolSchema
          type: string
          hidden: true
          id: customTool_0-input-customToolSchema-string
          display: true
        - label: Custom Tool Func
          name: customToolFunc
          type: string
          hidden: true
          id: customTool_0-input-customToolFunc-string
          display: true
      inputAnchors: []
      inputs:
        selectedTool: [% date_tool_id %]
        returnDirect: ""
        customToolName: ""
        customToolDesc: ""
        customToolSchema: ""
        customToolFunc: ""
      outputAnchors:
        - id: customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable
          name: customTool
          label: CustomTool
          description: Use custom tool you've created in Flowise within chatflow
          type: CustomTool | Tool | StructuredTool | Runnable
      outputs: {}
      selected: false
    width: 300
    height: 407
    selected: false
    positionAbsolute:
      x: 350
      y: 1125.5
    dragging: false
  - id: calculator_0
    position:
      x: 0
      y: 1725
    type: customNode
    data:
      id: calculator_0
      label: Calculator
      version: 1
      name: calculator
      type: Calculator
      baseClasses:
        - Calculator
        - Tool
        - StructuredTool
        - Runnable
      category: Tools
      description: Perform calculations on response
      inputParams: []
      inputAnchors: []
      inputs: {}
      outputAnchors:
        - id: calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable
          name: calculator
          label: Calculator
          description: Perform calculations on response
          type: Calculator | Tool | StructuredTool | Runnable
      outputs: {}
      selected: false
    width: 300
    height: 159
    selected: false
    positionAbsolute:
      x: 0
      y: 1725
    dragging: false
  - id: serpAPI_0
    position:
      x: 350
      y: 1575
    type: customNode
    data:
      id: serpAPI_0
      label: Serp API
      version: 1
      name: serpAPI
      type: SerpAPI
      baseClasses:
        - SerpAPI
        - Tool
        - StructuredTool
        - Runnable
      category: Tools
      description: Wrapper around SerpAPI - a real-time API to access Google search results
      inputParams:
        - label: Connect Credential
          name: credential
          type: credential
          credentialNames:
            - serpApi
          id: serpAPI_0-input-credential-credential
          display: true
      inputAnchors: []
      inputs: {}
      outputAnchors:
        - id: serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool|Runnable
          name: serpAPI
          label: SerpAPI
          description: Wrapper around SerpAPI - a real-time API to access Google search results
          type: SerpAPI | Tool | StructuredTool | Runnable
      outputs: {}
      credential: [% serp_cred_id %]
      selected: false
    width: 300
    height: 306
    selected: false
    positionAbsolute:
      x: 350
      y: 1575
    dragging: false
edges:
  - source: chatOpenAI_0
    sourceHandle: chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable
    target: toolAgent_0
    targetHandle: toolAgent_0-input-model-BaseChatModel
    type: buttonedge
    id: chatOpenAI_0-chatOpenAI_0-output-chatOpenAI-ChatOpenAI|BaseChatOpenAI|BaseChatModel|BaseLanguageModel|Runnable-toolAgent_0-toolAgent_0-input-model-BaseChatModel
  - source: inMemoryCache_0
    sourceHandle: inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache
    target: chatOpenAI_0
    targetHandle: chatOpenAI_0-input-cache-BaseCache
    type: buttonedge
    id: inMemoryCache_0-inMemoryCache_0-output-inMemoryCache-InMemoryCache|BaseCache-chatOpenAI_0-chatOpenAI_0-input-cache-BaseCache
  - source: bufferWindowMemory_0
    sourceHandle: bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory
    target: toolAgent_0
    targetHandle: toolAgent_0-input-memory-BaseChatMemory
    type: buttonedge
    id: bufferWindowMemory_0-bufferWindowMemory_0-output-bufferWindowMemory-BufferWindowMemory|BaseChatMemory|BaseMemory-toolAgent_0-toolAgent_0-input-memory-BaseChatMemory
  - source: customTool_0
    sourceHandle: customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable
    target: toolAgent_0
    targetHandle: toolAgent_0-input-tools-Tool
    type: buttonedge
    id: customTool_0-customTool_0-output-customTool-CustomTool|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool
  - source: calculator_0
    sourceHandle: calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable
    target: toolAgent_0
    targetHandle: toolAgent_0-input-tools-Tool
    type: buttonedge
    id: calculator_0-calculator_0-output-calculator-Calculator|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool
  - source: serpAPI_0
    sourceHandle: serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool|Runnable
    target: toolAgent_0
    targetHandle: toolAgent_0-input-tools-Tool
    type: buttonedge
    id: serpAPI_0-serpAPI_0-output-serpAPI-SerpAPI|Tool|StructuredTool|Runnable-toolAgent_0-toolAgent_0-input-tools-Tool
