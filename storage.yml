---
# https://github.com/longhorn/charts/tree/v1.9.x/charts/longhorn#prerequisites
- name: Prepare nodes for Longhorn
  tags: prepare
  hosts: k8s_all
  gather_facts: false
  become: true
  vars_files: &vars_files
    - vars/kubernetes.yml
    - vars/monitoring.yml
    - vars/storage.yml
    - vars/minio.yml
  pre_tasks:
    - name: Is iscsi_tcp module loaded?
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html
      ansible.builtin.shell: |
        set -o pipefail
        lsmod | grep -q iscsi_tcp
      args:
        executable: /bin/bash
      register: iscsi_tcp
      changed_when: false
      failed_when: false

    - name: Is Longhorn already installed?
      become: false
      vars:
        # required kubernetes>=24.2 package only in user virtualenv
        ansible_python_interpreter: "{{ venv_python_interpreter }}"
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_info_module.html
      kubernetes.core.k8s_info:
        kubeconfig: "{{ rke_kubeconfig }}"
        api_version: v1
        kind: Service
        name: longhorn-backend
        namespace: "{{ longhorn_namespace }}"
      # installed only on RKE cluster for now
      when: inventory_hostname == rke_control_plane_host
      register: longhorn_installed
  tasks:
    - name: Load iscsi_tcp kernel module
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html
      ansible.builtin.command: modprobe iscsi_tcp
      when: iscsi_tcp.rc != 0
      changed_when: true

    - name: Enable and start iSCSI daemon
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/systemd_service_module.html
      ansible.builtin.systemd_service:
        name: iscsid
        state: started
        enabled: true
        daemon_reload: true

    # multipathd is known to have a breakage that affects Longhorn:
    # https://longhorn.io/kb/troubleshooting-volume-with-multipath/
    - name: Disable the multipath daemon
      ansible.builtin.systemd_service:
        name: multipathd
        state: stopped
        enabled: false

    # for some reason, multipathd service keeps getting
    # started despite being disabled, so also add iSCSI
    # to its blacklist to avoid Longhorn mount failures
    - name: iSCSI in multipath blacklist
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/blockinfile_module.html
      ansible.builtin.blockinfile:
        path: /etc/multipath.conf
        block: |
          blacklist {
              device {
                  vendor "IET" # iSCSI Enterprise Target
              }
          }

    - name: Run Longhorn environment check
      # run once in each cluster if
      # Longhorn not installed yet
      when: >-
        inventory_hostname in [
          k3s_control_plane_host,
          rke_control_plane_host
        ] and longhorn_installed.resources | default([]) is falsy
      become: false
      vars:
        # NOTE: depending on version, environment_check.sh may not be available
        branch: v{{ longhorn_chart_version | regex_replace('[0-9]+$', 'x') }}
        script_url: https://raw.githubusercontent.com/longhorn/longhorn/{{
          branch }}/scripts/environment_check.sh
      block:
        - name: Does environment_check.sh exist?
          ansible.builtin.shell: |
            # this curl command outputs only the HTTP status code
            curl -Iso /dev/null -w "%{http_code}" {{ script_url }}
          register: env_check_sh
          changed_when: false

        - name: Run environment_check.sh script
          ansible.builtin.shell: |
            # run Bash and source /etc/profile.d
            # scripts so that kubectl is in PATH
            exec /bin/bash -l <<'EOT'
            set -o pipefail

            # sed command strips colored output
            curl -s {{ script_url }} | bash | \
              sed -r 's/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g'
            EOT
          when: env_check_sh.stdout == '200'
          register: env_check
          changed_when: false
          timeout: 300

        - name: Show environment check results
          # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html
          ansible.builtin.debug:
            msg: "{{ env_check.stdout }}"
          when: env_check.stdout is defined
          # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/search_test.html
          failed_when: env_check.stdout is search('\\[ERROR\\]')
  any_errors_fatal: true

# create LVM logical volume /data for
# Kubernetes local persistent volumes
- name: Create LV for Longhorn PVs
  tags: lvs
  hosts: cluster
  become: true
  vars_files:
    - vars/storage.yml
  vars:
    lv_dev: /dev/{{ data_lv.vg }}/{{ data_lv.lv }}
  pre_tasks:
    - name: Check if LV already exists
      ansible.builtin.command: lvdisplay -c {{ lv_dev }}
      register: lv_exists
      changed_when: false
      failed_when: false
  tasks:
    - name: Create {{ data_lv.size }} logical volume
      # https://docs.ansible.com/ansible/latest/collections/community/general/lvol_module.html
      community.general.lvol:
        lv: "{{ data_lv.lv }}"
        vg: "{{ data_lv.vg }}"
        size: "{{ data_lv.size }}"
        state: present
        resizefs: true
      # lvdisplay returns 5 if LV not found
      when: lv_exists.rc == 5

    - name: Create {{ data_lv.fs | upper }} filesystem
      # https://docs.ansible.com/ansible/latest/collections/community/general/filesystem_module.html
      community.general.filesystem:
        fstype: "{{ data_lv.fs }}"
        dev: "{{ lv_dev }}"
        resizefs: true

    - name: Mount LV on {{ data_lv.mount }}
      # https://docs.ansible.com/ansible/latest/collections/ansible/posix/mount_module.html
      ansible.posix.mount:
        src: "{{ lv_dev }}"
        path: "{{ data_lv.mount }}"
        fstype: "{{ data_lv.fs }}"
        state: mounted
  any_errors_fatal: true

- name: Install Longhorn components
  tags: longhorn
  # install just on RKE cluster for now
  hosts: "{{ rke_control_plane_host }}"
  gather_facts: false
  vars_files: *vars_files
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
    kubeconfig: "{{ rke_kubeconfig }}"
  pre_tasks:
    - name: Get CA certificates from PKI
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_tasks_module.html
      ansible.builtin.include_tasks: tasks/pki/cacerts.yml
      when: ca_certificates is not defined

    - name: Is the monitoring stack ready?
      ansible.builtin.include_tasks: tasks/monitoring/stackready.yml
      when: monitoring_stack_ready is not defined
  tasks:
    # https://www.suse.com/c/rancher_blog/using-minio-as-backup-target-for-rancher-longhorn
    - name: Create MinIO credentials secret
      vars:
        secret_name: "{{ longhorn_secrets['minio'] }}"
        secret_data:
          AWS_ACCESS_KEY_ID: longhorn
          AWS_SECRET_ACCESS_KEY: "{{ minio_client_pass }}"
          AWS_ENDPOINTS: "{{ minio_service_url }}"
          AWS_CERT: "{{ ca_certificates[1] }}"
        secret_ns: "{{ longhorn_namespace }}"
        release: "{{ longhorn_release_name }}"
      ansible.builtin.include_tasks: tasks/k8s/secrets/generic.yml

    # https://longhorn.io/docs/latest/deploy/install/install-with-helm
    # https://github.com/longhorn/charts/tree/v1.9.x/charts/longhorn
    - name: Install Longhorn Helm chart
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/helm_module.html
      kubernetes.core.helm:
        kubeconfig: "{{ kubeconfig }}"
        chart_repo_url: https://charts.longhorn.io
        chart_ref: longhorn
        chart_version: "{{ longhorn_chart_version }}"
        release_name: "{{ longhorn_release_name }}"
        release_namespace: "{{ longhorn_namespace }}"
        release_values: "{{ longhorn_chart_values }}"
        atomic: true
      timeout: 300

    - name: Get default "longhorn" storage class
      kubernetes.core.k8s_info:
        kubeconfig: "{{ rke_kubeconfig }}"
        api_version: storage.k8s.io/v1
        kind: StorageClass
        name: "{{ storage_classes['default'] }}"
      register: longhorn_sc

    # other than a single replica, use the same settings as the default storage class;
    # however, on Longhorn upgrade, this task may fail if the storage class parameters
    # change because "updates to parameters are forbidden"--simply delete this storage
    # class manually, then re-run this playbook
    - name: Add "longhorn-single" storage class
      vars:
        definition: |
          {# other than name, ignore all metadata
             added by  Kubernetes and Longhorn #}
          {% set sc = longhorn_sc.resources[0] %}
          {% set _  = sc.update({
               'metadata': {
                 'name': storage_classes['single']
               }
             }) %}
          {% set _ = sc.parameters.update({
               'numberOfReplicas': '1'
             }) %}
          {{ sc }}
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_module.html
      kubernetes.core.k8s:
        kubeconfig: "{{ rke_kubeconfig }}"
        definition: "{{ definition }}"
        validate:
          fail_on_error: false
        state: present
        apply: true
  any_errors_fatal: true

# https://computingforgeeks.com/configure-nfs-as-kubernetes-persistent-volume-storage/
- name: Install NFS dynamic provisioner
  tags: nfs
  hosts:
    - "{{ k3s_control_plane_host }}"
    - "{{ rke_control_plane_host }}"
  gather_facts: false
  vars_files: *vars_files
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
    # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/ternary_filter.html
    cluster: "{{ (inventory_hostname == k3s_control_plane_host) | ternary('k3s','rke') }}"
  tasks:
    - name: Install NFS provisioner Helm chart
      vars:
        provisioners: "{{ nfs_provisioners | selectattr('cluster', '==', cluster) }}"
        mount_options: "{{ nfs_mount_opts | split(',') }}"
        storage_class: |
          {# https://docs.ansible.com/ansible/latest/collections/ansible/builtin/combine_filter.html #}
          {% set sc = item.storageClass | ansible.builtin.combine({
               'name': item.storageClass.name | default('nfs-'~ item.name)
             }) %}
          {{ sc }}
      kubernetes.core.helm:
        kubeconfig: "{{ vars[cluster ~'_kubeconfig'] }}"
        chart_repo_url: https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner
        chart_ref: nfs-subdir-external-provisioner
        release_name: "{{ item.name }}"
        # https://github.com/kubernetes-sigs/nfs-subdir-external-provisioner/tree/master/charts/nfs-subdir-external-provisioner/values.yaml
        release_values:
          nfs:
            server: "{{ item.server }}"
            path: "{{ item.path }}"
            mountOptions: "{{ mount_options }}"
          storageClass: "{{ storage_class }}"
        release_namespace: nfs-provisioner
        create_namespace: true
        atomic: true
      loop: "{{ provisioners }}"
      loop_control:
        label: "{{ item.name }}"
  any_errors_fatal: true

- name: Configure storage dashboards
  tags: dashboards
  hosts: "{{ rke_control_plane_host }}"
  gather_facts: false
  vars_files: *vars_files
  tasks:
    - name: Import Grafana dashboards
      vars:
        dashboards: "{{ storage_grafana_dashboards }}"
      ansible.builtin.include_tasks: tasks/grafana/dashboards.yml
      when: grafana_api_server_online | default(true)
  any_errors_fatal: true
