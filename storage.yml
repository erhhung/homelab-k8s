---
# https://github.com/longhorn/charts/tree/v1.9.x/charts/longhorn#prerequisites
- name: Prepare nodes for Longhorn
  tags: prepare
  hosts: k8s_hosts
  become: true
  vars_files: &vars_files
    - vars/kubernetes.yml
    - vars/monitoring.yml
    - vars/storage.yml
    - vars/basics.yml
    - vars/minio.yml
  pre_tasks:
    - name: Is iscsi_tcp module loaded?
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html
      ansible.builtin.shell: |
        set -o pipefail

        # ignore SIGPIPE (rc=141) with pipefail:
        # https://www.pixelbeat.org/programming/sigpipe_handling.html
        { lsmod || true; } | grep -q iscsi_tcp
      args:
        executable: /bin/bash
      register: iscsi_tcp
      changed_when: false
      failed_when: false

    - name: Ensure DNS resolution works
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_tasks_module.html
      ansible.builtin.include_tasks: tasks/dns/check.yml

    - name: Is Longhorn already installed?
      become: false
      vars:
        # required kubernetes>=24.2 package only in user virtualenv
        ansible_python_interpreter: "{{ venv_python_interpreter }}"
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_info_module.html
      kubernetes.core.k8s_info:
        kubeconfig: "{{ rke_kubeconfig }}"
        api_version: v1
        kind: Service
        name: longhorn-backend
        namespace: "{{ longhorn_namespace }}"
      # installed only on RKE cluster for now
      when: inventory_hostname == rke_control_plane_host
      register: longhorn_installed
  tasks:
    - name: Load iscsi_tcp kernel module
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html
      ansible.builtin.command: modprobe iscsi_tcp
      when: iscsi_tcp.rc != 0
      changed_when: true

    - name: Enable and start iSCSI daemon
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/systemd_service_module.html
      ansible.builtin.systemd_service:
        name: iscsid
        state: started
        enabled: true
        daemon_reload: true

    # multipathd is known to have a breakage that affects Longhorn:
    # https://longhorn.io/kb/troubleshooting-volume-with-multipath
    - name: Disable the multipath daemon
      ansible.builtin.systemd_service:
        name: multipathd
        state: stopped
        enabled: false

    # for some reason, multipathd service keeps getting
    # started despite being disabled, so also add iSCSI
    # to its blacklist to avoid Longhorn mount failures
    - name: iSCSI in multipath blacklist
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/blockinfile_module.html
      ansible.builtin.blockinfile:
        path: /etc/multipath.conf
        block: |
          blacklist {
              device {
                  vendor "IET" # iSCSI Enterprise Target
              }
          }

    - name: Run Longhorn environment check
      # run once in each cluster if
      # Longhorn not installed yet
      when:
        - longhorn_installed.resources | default([]) is falsy
        - inventory_hostname in [
          k3s_control_plane_host,
          rke_control_plane_host]
      become: false
      vars:
        # NOTE: depending on version, environment_check.sh may not be available
        branch: v{{ longhorn_chart_version | regex_replace('[0-9]+$', 'x') }}
        script_url: https://raw.githubusercontent.com/longhorn/longhorn/{{
          branch }}/scripts/environment_check.sh
      block:
        - name: Does environment_check.sh exist?
          ansible.builtin.shell: |
            # this curl command outputs only the HTTP status code
            curl -Iso /dev/null -w "%{http_code}" {{ script_url }}
          register: env_check_sh
          changed_when: false

        - name: Run environment_check.sh script
          ansible.builtin.shell: |
            # run Bash and source /etc/profile.d
            # scripts so that kubectl is in PATH
            exec /bin/bash -l <<'EOT'
            set -o pipefail

            # sed command strips colored output
            curl -s {{ script_url }} | bash | \
              sed -r 's/\x1B\[([0-9]{1,3}(;[0-9]{1,2})?)?[mGK]//g'
            EOT
          when: env_check_sh.stdout == '200'
          register: env_check
          changed_when: false
          timeout: 300

        - name: Show environment check results
          # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html
          ansible.builtin.debug:
            msg: "{{ env_check.stdout }}"
          when: env_check.stdout is defined
          # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/search_test.html
          failed_when: env_check.stdout is search('\\[ERROR\\]')

# create LVM logical volume /data for
# Kubernetes local persistent volumes
- name: Create LV for Longhorn PVs
  tags: lvs
  hosts: rke_cluster
  become: true
  vars_files:
    - vars/storage.yml
  vars:
    lv_dev: /dev/{{ data_lv.vg }}/{{ data_lv.lv }}
  pre_tasks:
    - name: Check if LV already exists
      ansible.builtin.command: lvdisplay -c {{ lv_dev }}
      register: lv_exists
      changed_when: false
      failed_when: false
  tasks:
    - name: Create {{ data_lv.size }} logical volume
      # https://docs.ansible.com/ansible/latest/collections/community/general/lvol_module.html
      community.general.lvol:
        lv: "{{ data_lv.lv }}"
        vg: "{{ data_lv.vg }}"
        size: "{{ data_lv.size }}"
        state: present
        resizefs: true
      # lvdisplay returns 5 if LV not found
      when: lv_exists.rc == 5

    - name: Create {{ data_lv.fs | upper }} filesystem
      # https://docs.ansible.com/ansible/latest/collections/community/general/filesystem_module.html
      community.general.filesystem:
        fstype: "{{ data_lv.fs }}"
        dev: "{{ lv_dev }}"
        resizefs: true

    - name: Mount LV on {{ data_lv.mount }}
      # https://docs.ansible.com/ansible/latest/collections/ansible/posix/mount_module.html
      ansible.posix.mount:
        src: "{{ lv_dev }}"
        path: "{{ data_lv.mount }}"
        fstype: "{{ data_lv.fs }}"
        state: mounted

- name: Install Longhorn components
  tags: longhorn
  # install just on RKE cluster for now
  hosts: "{{ rke_control_plane_host }}"
  vars_files: *vars_files
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
    kubeconfig: "{{ rke_kubeconfig }}"
  pre_tasks:
    - name: Get CA certificates from PKI
      ansible.builtin.include_tasks: tasks/pki/cacerts.yml
      when: ca_certificates is undefined

    - name: Is the monitoring stack ready?
      ansible.builtin.include_tasks: tasks/monitoring/stackready.yml
      when: monitoring_stack_ready is undefined

    - name: Does RecurringJob CRD exist?
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: apiextensions.k8s.io/v1
        kind: CustomResourceDefinition
        # name must be in plural form!
        name: recurringjobs.longhorn.io
      register: crd_info
  tasks:
    # https://www.suse.com/c/rancher_blog/using-minio-as-backup-target-for-rancher-longhorn
    # (MinIO hasn't been installed yet, but
    # prepare the credentials secret first)
    - name: Create MinIO credentials secret
      vars:
        secret_name: "{{ longhorn_secrets['minio'] }}"
        secret_data:
          AWS_ACCESS_KEY_ID: longhorn
          AWS_SECRET_ACCESS_KEY: "{{ minio_client_pass }}"
          AWS_ENDPOINTS: "{{ minio_service_url }}"
          AWS_CERT: "{{ ca_certificates[1] }}"
        secret_ns: "{{ longhorn_namespace }}"
      ansible.builtin.include_tasks: tasks/k8s/secrets/generic.yml

    # adopt new storage class into
    # Helm release after first run
    - name: Get Longhorn "single" storage class
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: storage.k8s.io/v1
        kind: StorageClass
        name: "{{ storage_classes['single'] }}"
      register: single_sc

    - name: Install Longhorn Helm chart
      vars:
        sc_ref: storage.k8s.io/v1 StorageClass {{ storage_classes['single'] }}
        jobs: |
          {% set jobs = [] %}
          {% for job in longhorn_recurring_jobs %}
          {%   set _  = jobs.append({
                'name': job.name,
                'def':  {
                  'apiVersion': 'longhorn.io/v1beta2',
                  'kind':       'RecurringJob',
                  'metadata': {
                    'name': job.name,
                  },
                  'spec': job.spec,
                },
              })    %}
          {% endfor %}
          {{ jobs   }}
      block:
        # https://longhorn.io/docs/latest/deploy/install/install-with-helm
        - name: Install Longhorn Helm chart
          vars:
            repo_name: longhorn
            repo_url: https://charts.longhorn.io
            chart_ref: longhorn
            chart_ver: "{{ longhorn_chart_version }}"
            release: "{{ longhorn_release_name }}"
            release_ns: "{{ longhorn_namespace }}"
            values: "{{ longhorn_chart_values }}"

            extras: # adopt extra resources into Helm release
              - v1 Secret {{ longhorn_secrets['minio'] }}
              - "{{ sc_ref                      if single_sc.resources is truthy else '' }}"
              - "{{ jobs | map(attribute='def') if  crd_info.resources is truthy else [] }}"
          ansible.builtin.include_tasks: tasks/helm/helmfile.yml

        # (job CRs can't be added to .extraObjects in chart
        # values because the CRDs haven't been created yet)
        - name: Add Longhorn recurring job
          # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_module.html
          kubernetes.core.k8s:
            kubeconfig: "{{ kubeconfig }}"
            definition: "{{ item.def   }}"
            namespace: "{{ longhorn_namespace }}"
            state: present
            apply: true
          loop: "{{ jobs }}"
          loop_control:
            label: "{{ item.name }}"
          when: crd_info.resources is falsy

    - name: Get default "longhorn" storage class
      kubernetes.core.k8s_info:
        kubeconfig: "{{ kubeconfig }}"
        api_version: storage.k8s.io/v1
        kind: StorageClass
        name: "{{ storage_classes['default'] }}"
      register: default_sc

    # other than a single replica, use the same settings as the default storage class;
    # however, on Longhorn upgrade, this task may fail if the storage class parameters
    # change because "updates to parameters are forbidden"--simply delete this storage
    # class manually, then re-run this playbook
    - name: Add "longhorn-single" storage class
      vars:
        # besides name, ignore all metadata
        # added by  Kubernetes and Longhorn
        definition: |
          {% set sc = default_sc.resources[0] %}
          {% set _  = sc.update({
               'metadata': {
                 'name': storage_classes['single']
               }
             }) %}
          {% set _ = sc.parameters.update({
               'numberOfReplicas': '1'
             }) %}
          {{ sc }}
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        definition: "{{ definition }}"
        validate:
          fail_on_error: false
        state: present
        apply: true

# https://computingforgeeks.com/configure-nfs-as-kubernetes-persistent-volume-storage
- name: Install NFS dynamic provisioner
  tags: nfs
  hosts:
    - "{{ k3s_control_plane_host }}"
    - "{{ rke_control_plane_host }}"
  vars_files: *vars_files
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
    # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/ternary_filter.html
    cluster: "{{ (inventory_hostname in groups['k3s_cluster']) | ternary('k3s','rke') }}"
    kubeconfig: "{{ vars[cluster ~'_kubeconfig'] }}"
  tasks:
    - name: Install NFS provisioner Helm chart
      vars:
        provisioners: "{{ nfs_provisioners | selectattr('cluster', '==', cluster) }}"
        values_:
          nfs:
            server: "{{ item.server }}"
            path: "{{   item.path   }}"
            mountOptions: "{{ nfs_mount_opts }}"
          storageClass: |
            {% set sc = item.storageClass | ansible.builtin.combine({
                'name': item.storageClass.name | default('nfs-'~ item.name)
               }) %}
            {{ sc }}

        # === Inputs ===
        tmpdir_name: nfs-provisioner-{{ item.name }}
        repo_name: nfs
        repo_url: https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner
        chart_ref: nfs-subdir-external-provisioner
        chart_ver: "{{ nfs_provisioner_chart_version }}"
        release_ns: "{{ nfs_provisioner_namespace }}"
        release: "{{ item.name }}"
        # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/combine_filter.html
        values: "{{ values_ | ansible.builtin.combine(nfs_provisioner_chart_values) }}"
      ansible.builtin.include_tasks: tasks/helm/helmfile.yml
      loop: "{{ provisioners }}"
      loop_control:
        label: "{{ item.name }}"

- name: Configure storage dashboards
  tags: dashboards
  hosts: localhost
  vars_files: *vars_files
  tasks:
    - name: Import Grafana dashboards
      vars:
        dashboards: "{{ storage_grafana_dashboards }}"
      ansible.builtin.include_tasks: tasks/grafana/dashboards.yml
      when: grafana_api_server_online | default(true)
