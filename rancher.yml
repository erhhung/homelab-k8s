---
# https://docs.k3s.io/installation/configuration
- name: Install single-node K3s cluster
  tags: k3s
  hosts: rancher
  gather_facts: false
  become: true
  vars_files:
    - vars/kubernetes.yml
    - vars/rancher.k3s.yml
  # pre_tasks:
  #   - name: Show configured server options
  #     # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html
  #     ansible.builtin.debug:
  #       # yeah, this prints the K3s token in plain text
  #       msg: "Server options: {{ k3s_opts | join(' ') }}"
  tasks:
    # https://docs.k3s.io/reference/env-variables
    - name: Install K3s service by script
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html
      ansible.builtin.shell: |
        set -o pipefail

        curl -sfL https://get.k3s.io | \
          INSTALL_K3S_VERSION={{ k3s_version }} \
          sh -s - {{ k3s_opts | join(' ') }}
      args:
        executable: /bin/bash
      register: install_k3s
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/search_test.html
      changed_when: install_k3s.stdout is not search('No change detected')

    - name: Wait for k3s service to start
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/systemd_service_module.html
      ansible.builtin.systemd_service:
        name: k3s
        state: started

    - name: Create /etc/profile.d/kubernetes.sh
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/copy_module.html
      ansible.builtin.copy:
        dest: /etc/profile.d/kubernetes.sh
        content: |
          # kubectl and crictl are in /usr/local/bin
          export KUBECONFIG={{ k3s_kubeconfig }}
          export CRI_CONFIG_FILE={{ k3s_crictl_config }}
          export CONTAINER_RUNTIME_ENDPOINT={{ containerd_socket }}
        mode: "0644"

    - name: Allow admin user to use crictl
      vars:
        file_path: "{{ item.path }}"
        file_mode: "{{ item.mode }}"
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_tasks_module.html
      ansible.builtin.include_tasks: tasks/fs/readable.yml
      loop:
        - path: "{{ k3s_crictl_config }}"
        - path: "{{ containerd_socket }}"
          mode: "0666"

    - name: Merge kubeconfig into local
      vars:
        kubeconfig: "{{ k3s_kubeconfig }}"
        context: "{{ k3s_cluster_name }}"
        server: https://{{ k3s_fqdn }}:6443
      ansible.builtin.include_tasks: tasks/k8s/kubeconfig.yml
  any_errors_fatal: true

- name: Apply supplemental K3s configuration
  tags: configure
  hosts: "{{ k3s_control_plane_host }}"
  gather_facts: false
  vars_files:
    - vars/basics.yml
    - vars/kubernetes.yml
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
  tasks:
    # docker.io/bitnami/* images are no longer maintained
    # and have been migrated to docker.io/bitnamilegacy/*
    - name: Configure containerd registries
      become: true
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html
      ansible.builtin.template:
        src: "{{ template_dir }}/k3s/containerd/registries.yaml.j2"
        dest: /etc/rancher/k3s/registries.yaml
        mode: "0644"
      register: registries_yaml

    # https://docs.k3s.io/installation/packaged-components
    - name: Write HelmChartConfig manifests
      become: true
      ansible.builtin.template:
        src: "{{ template_dir }}/{{ item.src }}"
        dest: "{{ k3s_manifests_dir }}/{{ item.dest }}"
        mode: "0664"
      loop:
        - src: k3s/traefik.yaml.j2
          dest: traefik-config.yaml
      loop_control:
        label: "{{ item.dest }}"
      register: chart_configs

    - name: Restart k3s service
      # noqa no-handler
      when: >-
        registries_yaml is changed or
        chart_configs.results | map(attribute='changed') is any
      become: true
      block:
        - name: Stop k3s service
          ansible.builtin.systemd_service:
            name: k3s
            state: stopped

        - name: Let processes exit
          # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/pause_module.html
          ansible.builtin.pause:
            prompt: Please wait...
            seconds: 30

        - name: Start k3s service
          ansible.builtin.systemd_service:
            name: k3s
            state: started

        - name: Check k3s status
          # noqa command-instead-of-module
          ansible.builtin.command: systemctl is-active k3s
          changed_when: false
          register: is_active
          until: is_active.stdout | trim == 'active'
          retries: 20
          delay: 3

    - name: Apply additional node labels
      vars:
        labels: |
          {% set labels = {} %}
          {% for label in additional_node_labels %}
          {%   if 'rancher' in label.nodes %}
          {%     set _ = labels.update({label.label: label.value}) %}
          {%   endif %}
          {% endfor  %}
          {{ labels  }}
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_module.html
      kubernetes.core.k8s:
        kubeconfig: "{{ k3s_kubeconfig }}"
        api_version: v1
        kind: Node
        name: rancher
        definition:
          metadata:
            labels: "{{ labels }}"
        state: patched
      when: labels is truthy

    - name: Apply CoreDNS customizations
      vars:
        # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_lookup.html
        definition: "{{ lookup('ansible.builtin.template',
          template_dir ~ '/k3s/coredns.yaml.j2') }}"
      kubernetes.core.k8s:
        kubeconfig: "{{ k3s_kubeconfig }}"
        definition: "{{ definition }}"
        state: present
        apply: true
      notify: Restart coredns Deployment
  handlers:
    - name: Restart coredns Deployment
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html
      ansible.builtin.command:
        argv:
          - kubectl
          - --kubeconfig={{ k3s_kubeconfig }}
          - --namespace=kube-system
          - rollout
          - restart
          - deployment/coredns
      changed_when: true
  any_errors_fatal: true

# https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade
- name: Install Rancher Server on K3s
  tags: rancher
  hosts: "{{ k3s_control_plane_host }}"
  gather_facts: false
  vars_files:
    - vars/kubernetes.yml
    - vars/rancher.yml
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
    kubeconfig: "{{ k3s_kubeconfig }}"
    release: "{{ rancher_release_name }}"
  tasks:
    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/resources/add-tls-secrets
    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/resources/update-rancher-certificate
    - name: Create Rancher ingress secret
      vars:
        cert_desc: Rancher
        cert_file: rancher
        secret_name: "{{ rancher_secrets['ingress'] }}"
        secret_ns: "{{ rancher_namespace }}"
        if_changed: Redeploy RKE Rancher agents
      ansible.builtin.include_tasks: tasks/k8s/secrets/tls.pki.yml
      # sets pem_chain fact

    - name: Create Rancher CA certs secret
      vars:
        secret_name: "{{ rancher_secrets['ca-tls'] }}"
        secret_ns: "{{ rancher_namespace }}"
        create_ns: false
        secret_data:
          # pem_chain fact set by tasks/k8s/secrets/tls.pki.yml
          # above contains both intermediate and root CA certs
          cacerts.pem: "{{ pem_chain[1:] | join('\n') }}"
      ansible.builtin.include_tasks: tasks/k8s/secrets/generic.yml

    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster#install-the-rancher-helm-chart
    - name: Install Rancher Server Helm chart
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/helm_module.html
      kubernetes.core.helm:
        kubeconfig: "{{ kubeconfig }}"
        chart_repo_url: https://releases.rancher.com/server-charts/latest
        chart_ref: rancher
        chart_version: "{{ rancher_chart_version }}"
        release_name: "{{ rancher_release_name }}"
        release_namespace: "{{ rancher_namespace }}"
        release_values: "{{ rancher_chart_values }}"
        history_max: "{{ helm_max_history }}"
        atomic: true
        wait: true
      timeout: 600

    - name: Set Rancher Server settings
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        api_version: management.cattle.io/v3
        kind: Setting
        name: "{{ item.name }}"
        definition:
          value: "{{ item.value }}"
        state: patched
      loop:
        # address delay and failure caused by https://github.com/rancher/rancher/issues/16213
        - name: server-url
          value: https://{{ k3s_fqdn }}
        # bootstrap password will be changed in task
        # below, so skip UI to change admin password
        - name: first-login
          value: "false"
      loop_control:
        label: "{{ item.name }}"

    # https://github.com/rancher/cli
    - name: Install Rancher CLI utility
      become: true
      ansible.builtin.shell: |
        set -o pipefail

        REL="https://github.com/rancher/cli/releases/latest"
        VER=$(curl -Is $REL | sed -En 's/^location:.+\/tag\/(.+)\r$/\1/p')

        # check if latest version already installed
        BIN=$(command -v rancher) &> /dev/null && {
          ver=$(v=(`rancher --version`); echo ${v[-1]})
          [ "$ver" == "$VER" ] && exit 9 # no change
          BIN=$(dirname "$BIN")
        }
        ARCH=$(uname -m | sed -e  's/x86_64/amd64/' \
                              -e 's/aarch64/arm/')
        curl -fsSL "$REL/download/rancher-linux-$ARCH-$VER.tar.gz" | \
          tar -xz -C "${BIN:-/usr/local/bin}" --no-same-owner \
            --strip-components=2 ./rancher-$VER/rancher
      args:
        executable: /bin/bash
      register: install_cli
      changed_when: install_cli.rc == 0
      failed_when: install_cli.rc not in [0,9]

    - name: Import RKE cluster using API
      # noqa command-instead-of-shell
      ansible.builtin.shell: |-
        {{ lookup('ansible.builtin.template', template_dir ~ '/rancher/importrke.sh.j2') }}
      timeout: 600
      register: import_rke
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/search_test.html
      changed_when: import_rke.stdout is search('_CHANGED_')
      # outputs CLUSTER and REGISTER

    - name: Save RKE registration URL
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/set_fact_module.html
      ansible.builtin.set_fact:
        rke_cluster: |-
          {% set lines = import_rke.stdout_lines | select('search','^CLUSTER=') %}
          {{ lines[0].split('CLUSTER=')[1] if lines is truthy else none }}
        # used in cluster.yml
        rke_reg_url: |-
          {% set lines = import_rke.stdout_lines | select('search','^REGISTER=') %}
          {{ lines[0].split('REGISTER=')[1] if lines is truthy else none }}
      when: import_rke.rc == 0

    - name: Show RKE registration URL
      vars:
        is_defined: |
          {{ rke_reg_url is defined and
             rke_reg_url is truthy  }}
      ansible.builtin.debug:
        msg: |-
          rke_cluster: "{{ rke_cluster }}"
          rke_reg_url: {{ '"'~ rke_reg_url ~'"' if is_defined else '<undefined>' }}
  handlers:
    # force redeploy cattle-cluster-agent in RKE cluster if Rancher TLS secrets
    # have changed so that CATTLE_CA_CHECKSUM environment variable gets updated
    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/resources/update-rancher-certificate#4-reconfigure-rancher-agents-to-trust-the-private-ca
    # kubectl annotate clusters.management.cattle.io $HOMELAB_ID io.cattle.agent.force.deploy=true
    - name: Redeploy RKE Rancher agents
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        api_version: management.cattle.io/v3
        kind: Cluster
        name: "{{ rke_cluster }}"
        definition:
          metadata:
            annotations:
              io.cattle.agent.force.deploy: "true"
        state: patched
      when: rke_cluster is match('c-')
  any_errors_fatal: true
