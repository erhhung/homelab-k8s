---
# https://docs.k3s.io/installation/configuration
- name: Install single-node K3s cluster
  tags: k3s
  hosts: rancher
  gather_facts: false
  become: true
  vars_files:
    - vars/kubernetes.yml
    - vars/rancher.k3s.yml
  # pre_tasks:
  #   - name: Show configured server options
  #     # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/debug_module.html
  #     ansible.builtin.debug:
  #       # yeah, this prints the K3s token in plain text
  #       msg: "Server options: {{ k3s_opts | join(' ') }}"
  tasks:
    # https://docs.k3s.io/reference/env-variables
    - name: Install K3s service by script
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/shell_module.html
      ansible.builtin.shell: |
        set -o pipefail

        curl -sfL https://get.k3s.io | \
          INSTALL_K3S_VERSION={{ k3s_version }} \
          sh -s - {{ k3s_opts | join(' ') }}
      args:
        executable: /bin/bash
      register: install_k3s
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/search_test.html
      changed_when: install_k3s.stdout is not search('No change detected')

    - name: Wait for k3s service to start
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/systemd_service_module.html
      ansible.builtin.systemd_service:
        name: k3s
        state: started

    - name: Create /etc/profile.d/kubernetes.sh
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/copy_module.html
      ansible.builtin.copy:
        dest: /etc/profile.d/kubernetes.sh
        content: |
          # kubectl and crictl are in /usr/local/bin
          export KUBECONFIG={{ k3s_kubeconfig }}
          export CRI_CONFIG_FILE={{ k3s_crictl_config }}
          export CONTAINER_RUNTIME_ENDPOINT={{ containerd_socket }}
        mode: "0644"

    - name: Allow admin user to use crictl
      vars:
        file_path: "{{ item.path }}"
        file_mode: "{{ item.mode }}"
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/include_tasks_module.html
      ansible.builtin.include_tasks: tasks/fs/readable.yml
      loop:
        - path: "{{ k3s_crictl_config }}"
        - path: "{{ containerd_socket }}"
          mode: "0666"

    - name: Merge kubeconfig into local
      vars:
        kubeconfig: "{{ k3s_kubeconfig }}"
        context: "{{ k3s_cluster_name }}"
        server: https://{{ k3s_fqdn }}:6443
      ansible.builtin.include_tasks: tasks/k8s/kubeconfig.yml
  any_errors_fatal: true

- name: Apply supplemental K3s configuration
  tags: configure
  hosts: "{{ k3s_control_plane_host }}"
  gather_facts: false
  vars_files:
    - vars/basics.yml
    - vars/kubernetes.yml
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
  tasks:
    # https://docs.k3s.io/installation/packaged-components
    - name: Write HelmChartConfig manifests
      become: true
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_module.html
      ansible.builtin.template:
        src: "{{ template_dir }}/{{ item.src }}"
        dest: "{{ k3s_manifests_dir }}/{{ item.dest }}"
        mode: "0664"
      loop:
        - src: k3s/traefik.yaml.j2
          dest: traefik-config.yaml
      loop_control:
        label: "{{ item.dest }}"
      register: chart_configs

    - name: Restart k3s service
      # noqa no-handler
      when: >-
        chart_configs is defined and
        chart_configs.results  | map(attribute='changed') is any
      become: true
      block:
        - name: Stop k3s service
          ansible.builtin.systemd_service:
            name: k3s
            state: stopped

        - name: Let processes exit
          # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/pause_module.html
          ansible.builtin.pause:
            seconds: 30

        - name: Start k3s service
          ansible.builtin.systemd_service:
            name: k3s
            state: started

        - name: Check k3s status
          # noqa command-instead-of-module
          ansible.builtin.command: systemctl is-active k3s
          changed_when: false
          register: is_active
          until: is_active.stdout | trim == 'active'
          retries: 20
          delay: 3

    - name: Apply additional node labels
      vars:
        labels: |
          {% set labels = {} %}
          {% for label in additional_node_labels %}
          {%   if 'rancher' in label.nodes %}
          {%     set _ = labels.update({label.label: label.value}) %}
          {%   endif %}
          {% endfor  %}
          {{ labels  }}
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/k8s_module.html
      kubernetes.core.k8s:
        kubeconfig: "{{ k3s_kubeconfig }}"
        api_version: v1
        kind: Node
        name: rancher
        definition:
          metadata:
            labels: "{{ labels }}"
        state: patched
      when: labels is truthy

    - name: Apply CoreDNS customizations
      vars:
        # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/template_lookup.html
        definition: "{{ lookup('ansible.builtin.template',
          template_dir ~ '/k3s/coredns.yaml.j2') }}"
      kubernetes.core.k8s:
        kubeconfig: "{{ k3s_kubeconfig }}"
        definition: "{{ definition }}"
        state: present
        apply: true
      notify: Restart coredns Deployment
  handlers:
    - name: Restart coredns Deployment
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/command_module.html
      ansible.builtin.command:
        argv:
          - kubectl
          - --kubeconfig={{ k3s_kubeconfig }}
          - --namespace=kube-system
          - rollout
          - restart
          - deployment/coredns
      changed_when: true
  any_errors_fatal: true

# https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade
- name: Install Rancher Server on K3s
  tags: rancher
  hosts: "{{ k3s_control_plane_host }}"
  gather_facts: false
  vars_files:
    - vars/kubernetes.yml
    - vars/rancher.yml
  vars:
    # required kubernetes>=24.2 package only in user virtualenv
    ansible_python_interpreter: "{{ venv_python_interpreter }}"
    kubeconfig: "{{ k3s_kubeconfig }}"
    release: "{{ rancher_release_name }}"
  tasks:
    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/resources/add-tls-secrets
    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/resources/update-rancher-certificate
    - name: Create Rancher ingress secret
      vars:
        cert_desc: Rancher
        cert_file: rancher
        secret_name: "{{ rancher_secrets['ingress'] }}"
        secret_ns: "{{ rancher_namespace }}"
        if_changed: Redeploy RKE Rancher agents
      ansible.builtin.include_tasks: tasks/k8s/secrets/tls.pki.yml
      # sets pem_chain fact

    - name: Create Rancher CA certs secret
      vars:
        secret_name: "{{ rancher_secrets['ca-tls'] }}"
        secret_ns: "{{ rancher_namespace }}"
        create_ns: false
        secret_data:
          # pem_chain fact set by tasks/k8s/secrets/tls.pki.yml
          # above contains both intermediate and root CA certs
          cacerts.pem: "{{ pem_chain[1:] | join('\n') }}"
      ansible.builtin.include_tasks: tasks/k8s/secrets/generic.yml

    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/install-upgrade-on-a-kubernetes-cluster#install-the-rancher-helm-chart
    - name: Install Rancher Server Helm chart
      # https://docs.ansible.com/ansible/latest/collections/kubernetes/core/helm_module.html
      kubernetes.core.helm:
        kubeconfig: "{{ kubeconfig }}"
        chart_repo_url: https://releases.rancher.com/server-charts/latest
        chart_ref: rancher
        chart_version: "{{ rancher_chart_version }}"
        release_name: "{{ rancher_release_name }}"
        release_namespace: "{{ rancher_namespace }}"
        release_values: "{{ rancher_chart_values }}"
        history_max: "{{ helm_max_history }}"
        atomic: true
        wait: true
      timeout: 600

    - name: Set Rancher Server settings
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        api_version: management.cattle.io/v3
        kind: Setting
        name: "{{ item.name }}"
        definition:
          value: "{{ item.value }}"
        state: patched
      loop:
        # address delay and failure caused by https://github.com/rancher/rancher/issues/16213
        - name: server-url
          value: https://{{ k3s_fqdn }}
        # bootstrap password will be changed in task
        # below, so skip UI to change admin password
        - name: first-login
          value: "false"
      loop_control:
        label: "{{ item.name }}"

    # https://github.com/rancher/cli
    - name: Install Rancher CLI utility
      become: true
      ansible.builtin.shell: |
        set -o pipefail

        REL="https://github.com/rancher/cli/releases/latest"
        VER=$(curl -Is $REL | sed -En 's/^location:.+\/tag\/(.+)\r$/\1/p')

        # check if latest version already installed
        BIN=$(command -v rancher) &> /dev/null && {
          ver=$(v=(`rancher --version`); echo ${v[-1]})
          [ "$ver" == "$VER" ] && exit 9 # no change
          BIN=$(dirname "$BIN")
        }
        ARCH=$(uname -m | sed -e  's/x86_64/amd64/' \
                              -e 's/aarch64/arm/')
        curl -fsSL "$REL/download/rancher-linux-$ARCH-$VER.tar.gz" | \
          tar -xz -C "${BIN:-/usr/local/bin}" --no-same-owner \
            --strip-components=2 ./rancher-$VER/rancher
      args:
        executable: /bin/bash
      register: install_cli
      changed_when: install_cli.rc == 0
      failed_when: >-
        install_cli.rc != 0 and
        install_cli.rc != 9

    - name: Import RKE cluster using API
      ansible.builtin.shell: |
        # restart Bash and load .bash_aliases
        # in order to use my custom functions
        exec /bin/bash <<'EOF'
        set -o pipefail

        TOKEN_DESC="Ansible session"
        ADMIN_PASS="{{ rancher_admin_pass }}"
        # .bash_aliases sources .rancher_api
        . .bash_aliases || exit $?

        if [ "$ADMIN_PASS" ]; then
          # if .rancher_api logged in with $ADMIN_PASS instead of
          # $BOOTSTRAP_PASS, ADMIN_PASS would have been unset, so
          # change the default password so user won`t be prompted
          echo >&2 "Changing default password..."
          rancher_api post "users?action=changepassword" @- <<EOT
        {
          "currentPassword": "$BOOTSTRAP_PASS",
              "newPassword":     "$ADMIN_PASS"
        }
        EOT
          echo "_CHANGED_ admin password set."
        fi

        # when .rancher_api (templates/rancher/api.sh.j2)
        # was sourced above, it would have exported both
        # cluster and project ID env vars if registered
        cluster="{{ rke_cluster_name }}"
        id_var="${cluster^^}_ID"
        cluster_id="${!id_var}"

        get_state() {
          rancher_api get clusters/$cluster_id | \
            jq -r '.state // empty'
        }
        if [ ! "$cluster_id" ]; then
          # RKE cluster not imported yet
          # import using the Rancher API
          echo >&2 "Importing RKE cluster..."
          cluster_id=$(rancher_api post clusters @- <<'EOT' | jq -r '.id // empty'
        {
          "import":      true,
          "type":        "cluster",
          "name":        "{{ rke_cluster_name }}",
          "description": "{{ rke_cluster_desc }}"
        }
        EOT
          )
          [ "$cluster_id" ] || {
            echo >&2 "Cluster import failed!"
            exit 1
          }
          echo "_CHANGED_ cluster imported."
          {
          echo -n "Waiting for cluster state to be pending.."
          until [ "$(get_state)" == pending ]; do
            echo -n .
            sleep 1
          done
          echo OK
          }   >&2
          export_variables
        fi
        # output ID for extraction
        echo "CLUSTER=$cluster_id"

        if [ "$(get_state)" != active ]; then
          # get cluster registration manifest URL so
          # it can be applied  on control plane node
          echo >&2 "Getting registration manifest URL..."
          reg_url=$(rancher_api get "clusters/$cluster_id/clusterregistrationtokens" | \
            \
            jq --arg baseUrl "$RANCHER_URL" -r '.data[] |
              select(.name == "default-token") |
                if (.manifestUrl // "") != "" then
                  .manifestUrl
                elif (.token // "") != "" then
                  "\($baseUrl)/v3/import/\(.token)_\(.clusterId).yaml"
                else empty
                end
              ')
          # output registration URL for extraction
          [ "$reg_url" ] && echo "REGISTER=$reg_url"
        fi

        # customize cluster appearance in the Rancher UI
        echo >&2 "Applying Rancher UI customizations..."
        rancher_api put "clusters/$cluster_id" @- <<'EOT' | \
          jq -cM '.annotations | with_entries(select(.key | startswith("ui.rancher")))' >&2
        {
          "name": "{{ rke_cluster_name }}",
          "annotations": {
            "ui.rancher/badge-color":      "{{ ui_badge_color }}",
            "ui.rancher/badge-icon-text":  "{{ ui_badge_icon }}",
            "ui.rancher/badge-text":       "{{ ui_badge_text }}"
          }
        }
        EOT

        # perform CLI login if not already
        config="$HOME/.rancher/cli2.json"
        [ -f $config ] && \
          [ "$(jq -r '.Servers[.CurrentServer].tokenKey // empty' $config)" ] || {

          # request a long-lived token
          echo >&2 "Requesting Rancher CLI token..."
          token=$(get_token "CLI token")
          id_var="${cluster^^}_DEFAULT_ID"

          echo >&2 "Performing Rancher CLI login..."
          rancher login "$RANCHER_URL" \
            --skip-verify      \
            --token   "$token" \
            --context "${!id_var}"

          echo "_CHANGED_ CLI logged in."
        }
        rancher_logout # delete $LOGIN_TOKEN
        EOF
      timeout: 600
      register: import_rke
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/search_test.html
      changed_when: import_rke.stdout is search('_CHANGED_')

    - name: Save RKE registration URL
      # https://docs.ansible.com/ansible/latest/collections/ansible/builtin/set_fact_module.html
      ansible.builtin.set_fact:
        rke_cluster: >-
          {% set lines = import_rke.stdout_lines | select('search','^CLUSTER=') | list -%}
          {{ lines[0].split('CLUSTER=')[1] if lines | length > 0 else none }}
        # used in cluster.yml
        rke_reg_url: >-
          {% set lines = import_rke.stdout_lines | select('search','^REGISTER=') | list -%}
          {{ lines[0].split('REGISTER=')[1] if lines | length > 0 else none }}
      when: import_rke.rc == 0

    - name: Show RKE registration URL
      vars:
        is_defined: >-
          rke_reg_url is defined  and
          rke_reg_url is not none and
          rke_reg_url != ''
      ansible.builtin.debug:
        msg: |-
          rke_cluster: "{{ rke_cluster }}"
          rke_reg_url: {{ '"'~ rke_reg_url ~'"' if is_defined else '<undefined>' }}
  handlers:
    # force redeploy cattle-cluster-agent in RKE cluster if Rancher TLS secrets
    # have changed so that CATTLE_CA_CHECKSUM environment variable gets updated
    # https://ranchermanager.docs.rancher.com/getting-started/installation-and-upgrade/resources/update-rancher-certificate#4-reconfigure-rancher-agents-to-trust-the-private-ca
    # kubectl annotate clusters.management.cattle.io $HOMELAB_ID io.cattle.agent.force.deploy=true
    - name: Redeploy RKE Rancher agents
      kubernetes.core.k8s:
        kubeconfig: "{{ kubeconfig }}"
        api_version: management.cattle.io/v3
        kind: Cluster
        name: "{{ rke_cluster }}"
        definition:
          metadata:
            annotations:
              io.cattle.agent.force.deploy: "true"
        state: patched
      when: rke_cluster is match('c-')
  any_errors_fatal: true
