rke_ha_mode: true # deploy 3 control plane nodes with kube-vip
rke_control_plane_group: "{{ 'control_plane_ha' if rke_ha_mode else 'control_plane' }}"
rke_workers_group: "{{ 'workers_ha' if rke_ha_mode else 'workers' }}"

# control plane hosts
k3s_control_plane_host: rancher
rke_control_plane_host: "{{ groups[rke_control_plane_group] | first }}"

cluster_domain: cluster.local

# K3s and RKE clusters
additional_node_labels:
  # all cluster nodes, including control plane node(s),
  # can run user workloads, so they are labeled worker
  # role (control plane nodes have already been labeled
  # with roles: "control-plane", "etcd", and "master")
  - label: node-role.kubernetes.io/worker
    value: "true"
    nodes: "{{ groups['cluster'] }}"

  # k8s2 is running on XCP-ng host with
  # Intel Alder Lake-P GT1 UHD Graphics
  - label: feature.node.kubernetes.io/gpu.preferred
    value: "true"
    nodes: ["k8s2"]

# location exported by KUBECONFIG variable
k3s_kubeconfig: /etc/rancher/k3s/k3s.yaml
rke_kubeconfig: /etc/rancher/rke2/rke2.yaml

# location exported by CRI_CONFIG_FILE variable
k3s_crictl_config: /var/lib/rancher/k3s/agent/etc/crictl.yaml
rke_crictl_config: /var/lib/rancher/rke2/agent/etc/crictl.yaml

rke_tls_dir: /var/lib/rancher/rke2/server/tls
rke_bin_dir: /var/lib/rancher/rke2/bin

container_runtime: containerd
containerd_config: /var/lib/rancher/rke2/agent/etc/containerd/config.toml
# location exported by CONTAINER_RUNTIME_ENDPOINT variable
containerd_socket: /run/k3s/containerd/containerd.sock

# https://docs.k3s.io/installation/packaged-components
k3s_manifests_dir: /var/lib/rancher/k3s/server/manifests
# https://docs.rke2.io/advanced#auto-deploying-manifests
rke_manifests_dir: /var/lib/rancher/rke2/server/manifests

k3s_cluster_name: rancher
rke_cluster_name: homelab
rke_cluster_desc: Erhhung's Kubernetes Cluster at Home

# remember to add rancher.fourteeners.local to pfSense DNS!
# https://docs.ansible.com/ansible/latest/playbook_guide/playbooks_filters.html#products
k3s_fqdn: "{{ [k3s_cluster_name] | product(search_domains) | map('join','.') | first }}"

# default CNs: kubernetes, kubernetes.default, kubernetes.default.svc,
# kubernetes.default.svc.cluster.local, cluster.local, localhost, k8s?
rke_fqdns: >
  {{ ([rke_cluster_name] + groups[rke_control_plane_group]) |
      product(search_domains) | map('join','.') | list }}

kube_system_domain: kube-system.svc.{{ cluster_domain }}
k3s_dns_host: kube-dns.{{ kube_system_domain }}
rke_dns_host: rke2-coredns-rke2-coredns.{{ kube_system_domain }}

k3s_ingress_class: traefik
rke_ingress_class: nginx

# remember to create nginx.pem with SANs:
#    homelab.fourteeners.local homelab 192.168.0.221
#       k8s1.fourteeners.local k8s1    192.168.0.171
#       k8s2.fourteeners.local k8s2    192.168.0.172
#       k8s3.fourteeners.local k8s3    192.168.0.173
# *.vcluster.fourteeners.local
# kubernetes
# kubernetes.default
# kubernetes.default.svc
# kubernetes.default.svc.cluster.local
#                        cluster.local 10.43.0.1
#                        localhost     127.0.0.1
nginx_tls_secret: rke2-ingress-nginx-default-tls

nginx_tcp_configmap: rke2-ingress-nginx-tcp-services
nginx_udp_configmap: rke2-ingress-nginx-udp-services

nginx_tcp_services:
  # https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services
  10022: gitlab/gitlab-shell:22
nginx_udp_services: {}

# virtual IP assigned by RKE2 kube-vip
rke_lb_vip: "{{ lb_vip_range.start }}"

# ensure names match those defined
# in manifests/priorityclasses.yaml
priority_classes:
  database: database-priority # 10000

# maximum number of revisions saved per release:
# https://docs.ansible.com/ansible/latest/collections/kubernetes/core/helm_module.html
helm_max_history: 3
